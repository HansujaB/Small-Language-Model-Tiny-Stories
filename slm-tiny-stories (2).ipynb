{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:54:35.436523Z","iopub.execute_input":"2025-07-09T04:54:35.436706Z","iopub.status.idle":"2025-07-09T04:54:40.822753Z","shell.execute_reply.started":"2025-07-09T04:54:35.436689Z","shell.execute_reply":"2025-07-09T04:54:40.821945Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport datasets\n\nds = load_dataset(\"roneneldan/TinyStories\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:54:40.823746Z","iopub.execute_input":"2025-07-09T04:54:40.823993Z","iopub.status.idle":"2025-07-09T04:54:56.612938Z","shell.execute_reply.started":"2025-07-09T04:54:40.823968Z","shell.execute_reply":"2025-07-09T04:54:56.612263Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"481311d14a1049ccb2a4c47399ffa792"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1cbfc52fa7048cda61339ceaafa299d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db8c259cf904fce8fd4f47b12feb363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad3318c7a8540a989e66db4fd48e6eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f44b34c0f94ecc900a27bc2769f45f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8eeac61b3404d7283963510513f334e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3798d1d10d34af3b971871bd1be8842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d0b8263e88d4b0fa24f0350dfea1095"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Tokenize the dataset \n1. into tokenids\n2. file train.bin and validation.bin  where we we store tokenids from entire dataset\n3. token ids store on disk rather than on the ram for efficient computations\n\nwe will   use byte pair encoding (gpt 2 subword tokenisation)(subwords tokenisation has all words characters an d subwords)","metadata":{}},{"cell_type":"code","source":"!pip install tiktoken \nimport tiktoken \nimport os\nimport numpy as np\nfrom tqdm.auto import tqdm\n\nenc= tiktoken.get_encoding(\"gpt2\")\n\ndef process(example):\n    ids=enc.encode_ordinary(example['text'])\n    out={'ids':ids,'len':len(ids)}\n    return out\n\nif not os.path.exists(\"train.bin\"):\n     tokenized=ds.map(\n         process,\n         remove_columns=['text'],\n         desc=\"tokenizing the splits\",\n         num_proc=8,\n         )\n     for split,dset in tokenized.items():\n         arr_len=np.sum(dset['len'], dtype=np.uint64)\n         filename=f\"{split}.bin\"\n         dtype=np.uint16 \n         arr=np.memmap(filename,dtype=dtype,mode='w+',shape=(arr_len,))\n         total_batches=1024\n         idx=0\n         for batch_idx in tqdm(range(total_batches), desc=f'writing{filename}'):\n             batch=dset.shard(num_shards=total_batches,index=batch_idx,contiguous=True).with_format('numpy')\n             arr_batch=np.concatenate(batch['ids'])\n             arr[idx: idx+len(arr_batch)]=arr_batch\n             idx+=len(arr_batch)\n     arr.flush()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:54:56.614532Z","iopub.execute_input":"2025-07-09T04:54:56.614934Z","iopub.status.idle":"2025-07-09T04:58:43.288540Z","shell.execute_reply.started":"2025-07-09T04:54:56.614897Z","shell.execute_reply":"2025-07-09T04:58:43.287467Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ab69afb0d043809fc0221dc675df9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizing the splits (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1321900cc0242f3a1b307d97926afe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"writingtrain.bin:   0%|          | 0/1024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8735a9de39c34fa98e6fd31d71e95652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"writingvalidation.bin:   0%|          | 0/1024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d46e020b6149ecb0ac1d83dd70cfee"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"Create Input Output batches for the dataset","metadata":{}},{"cell_type":"code","source":"def get_batch(split):\n    if(split=='train'):\n        data=np.memmap('train.bin', dtype=np.uint16 , mode='r')\n    else:\n        data=np.memmap('validation.bin', dtype=np.uint16 , mode='r')\n    ix=torch.randint(len(data)- block_size, (batch_size,))\n    x=torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n    y=torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n    if device_type=='cuda':\n        x , y=x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n    else:\n        x,y=x.to(device), y.to(device)\n    return x,y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:43.289890Z","iopub.execute_input":"2025-07-09T04:58:43.290246Z","iopub.status.idle":"2025-07-09T04:58:43.296928Z","shell.execute_reply.started":"2025-07-09T04:58:43.290206Z","shell.execute_reply":"2025-07-09T04:58:43.296251Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Define the SLM Model Architecture","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom dataclasses import dataclass\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom contextlib import nullcontext\nimport os\n\nclass LayerNorm(nn.Module):\n    def __init__(self, ndim, bias):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(ndim))\n        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n    def forward(self, x):\n        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n\nclass CausalSelfAttention(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        assert config.n_embd % config.n_head == 0\n        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n        self.attn_dropout = nn.Dropout(config.dropout)\n        self.resid_dropout = nn.Dropout(config.dropout)\n        self.n_head = config.n_head\n        self.n_embd = config.n_embd\n        self.flash = hasattr(F, 'scaled_dot_product_attention')\n        if not self.flash:\n            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n                                       .view(1, 1, config.block_size, config.block_size))\n\n    def forward(self, x):\n        B, T, C = x.size()\n        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n\n        if self.flash:\n            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n        else:\n            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n            att = F.softmax(att, dim=-1)\n            att = self.attn_dropout(att)\n            y = att @ v\n\n        y = y.transpose(1, 2).contiguous().view(B, T, C)\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n\nclass MLP(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n        self.gelu = nn.GELU()\n        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n        self.dropout = nn.Dropout(config.dropout)\n    def forward(self, x):\n        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n\nclass Block(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.ln1 = LayerNorm(config.n_embd, config.bias)\n        self.attn = CausalSelfAttention(config)\n        self.ln2 = LayerNorm(config.n_embd, config.bias)\n        self.mlp = MLP(config)\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))\n        x = x + self.mlp(self.ln2(x))\n        return x\n\n@dataclass\nclass GPTConfig:\n    block_size: int\n    vocab_size: int\n    n_layer: int\n    n_head: int\n    n_embd: int\n    dropout: float = 0.0\n    bias: bool = True\n\nclass GPT(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        self.transformer = nn.ModuleDict(dict(\n            wte=nn.Embedding(config.vocab_size, config.n_embd),\n            wpe=nn.Embedding(config.block_size, config.n_embd),\n            drop=nn.Dropout(config.dropout),\n            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n            ln_f=LayerNorm(config.n_embd, config.bias),\n        ))\n        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n\n        self.apply(self._init_weights)\n        for pn, p in self.named_parameters():\n            if pn.endswith('c_proj.weight'):\n                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n        device = idx.device\n        b, t = idx.size()\n        assert t <= self.config.block_size\n        pos = torch.arange(0, t, dtype=torch.long, device=device)\n\n        tok_emb = self.transformer.wte(idx)\n        pos_emb = self.transformer.wpe(pos)\n        x = self.transformer.drop(tok_emb + pos_emb)\n        for block in self.transformer.h:\n            x = block(x)\n        x = self.transformer.ln_f(x)\n\n        if targets is not None:\n            logits = self.lm_head(x)\n            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n            return logits, loss\n        else:\n            logits = self.lm_head(x[:, [-1], :])\n            return logits, None\n\n    @torch.no_grad()\n    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n        for _ in range(max_new_tokens):\n            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n            logits, _ = self(idx_cond)\n            logits = logits[:, -1, :] / temperature\n            if top_k is not None:\n                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n                logits[logits < v[:, [-1]]] = -float('Inf')\n            probs = F.softmax(logits, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat((idx, idx_next), dim=1)\n        return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:43.297807Z","iopub.execute_input":"2025-07-09T04:58:43.298080Z","iopub.status.idle":"2025-07-09T04:58:47.630372Z","shell.execute_reply.started":"2025-07-09T04:58:43.298062Z","shell.execute_reply":"2025-07-09T04:58:47.629612Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"config = GPTConfig(\n    vocab_size=50257,     # tokenizer's vocab size\n    block_size=128,     \n    n_layer=6,\n    n_head=6,\n    n_embd=384,\n    dropout=0.1,\n    bias=True\n)\n\nmodel = GPT(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:47.631145Z","iopub.execute_input":"2025-07-09T04:58:47.631345Z","iopub.status.idle":"2025-07-09T04:58:48.523943Z","shell.execute_reply.started":"2025-07-09T04:58:47.631330Z","shell.execute_reply":"2025-07-09T04:58:48.523211Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def estimate_loss(model):\n    out = {}\n    model.eval()\n    with torch.inference_mode():\n        for split in ['train', 'val']:\n            losses = torch.zeros(eval_iters)\n            for k in range(eval_iters):\n                X, Y = get_batch(split)\n                with ctx:\n                    logits, loss = model(X, Y)\n                losses[k] = loss.item()\n            out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:48.524774Z","iopub.execute_input":"2025-07-09T04:58:48.525076Z","iopub.status.idle":"2025-07-09T04:58:48.530483Z","shell.execute_reply.started":"2025-07-09T04:58:48.525049Z","shell.execute_reply":"2025-07-09T04:58:48.529754Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Training Config\nimport torch\nfrom contextlib import nullcontext\n\nlearning_rate = 1e-4 \nmax_iters = 30000 \nwarmup_steps = 1000 \nmin_lr = 5e-4 \neval_iters = 500 \nbatch_size = 32\nblock_size = 128\n\ngradient_accumulation_steps = 32 \n\ndevice =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n# note: float16 data type will automatically use a GradScaler\n\ndtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\nptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n\nctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n\ntorch.set_default_device(device)\ntorch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:48.531303Z","iopub.execute_input":"2025-07-09T04:58:48.531540Z","iopub.status.idle":"2025-07-09T04:58:48.788936Z","shell.execute_reply.started":"2025-07-09T04:58:48.531513Z","shell.execute_reply":"2025-07-09T04:58:48.788111Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ce66c905c30>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n\noptimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n\nscheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\nscheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\nscheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n\nscaler = torch.amp.GradScaler('cuda',enabled=(dtype == 'float16'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:48.791381Z","iopub.execute_input":"2025-07-09T04:58:48.791601Z","iopub.status.idle":"2025-07-09T04:58:52.147586Z","shell.execute_reply.started":"2025-07-09T04:58:48.791585Z","shell.execute_reply":"2025-07-09T04:58:52.146950Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"best_val_loss = float('inf')\nbest_model_params_path = \"best_model_params.pt\"\ntrain_loss_list, validation_loss_list = [], []\n\n# model is on the correct device\nmodel = model.to(device)\n\n# training loop\nfor epoch in tqdm(range(max_iters)):\n    if epoch % eval_iters == 0 and epoch != 0:\n        # Ensure estimate_loss uses the correct device\n        losses = estimate_loss(model)\n        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n        train_loss_list += [losses['train']]\n        validation_loss_list += [losses['val']]\n\n        if losses['val'] < best_val_loss:\n            best_val_loss = losses['val']\n            torch.save(model.state_dict(), best_model_params_path)\n\n    # Ensure X and y are on the correct device\n    X, y = get_batch(\"train\")\n    X, y = X.to(device), y.to(device)\n\n    with ctx:\n        logits, loss = model(X, y)\n        loss = loss / gradient_accumulation_steps\n        scaler.scale(loss).backward()\n\n    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad(set_to_none=True)\n    scheduler.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T04:58:52.148655Z","iopub.execute_input":"2025-07-09T04:58:52.149141Z","iopub.status.idle":"2025-07-09T07:28:11.837277Z","shell.execute_reply.started":"2025-07-09T04:58:52.149121Z","shell.execute_reply":"2025-07-09T07:28:11.836546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8339c27b64c4dceab6dfb508c65405f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 500: train loss 9.3444, val loss 9.3535\nThe current learning rate: 0.00007\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1000: train loss 8.4339, val loss 8.4408\nThe current learning rate: 0.00010\nEpoch 1500: train loss 7.5003, val loss 7.4978\nThe current learning rate: 0.00010\nEpoch 2000: train loss 6.6587, val loss 6.6552\nThe current learning rate: 0.00010\nEpoch 2500: train loss 5.9675, val loss 5.9648\nThe current learning rate: 0.00010\nEpoch 3000: train loss 5.4766, val loss 5.4714\nThe current learning rate: 0.00010\nEpoch 3500: train loss 5.0810, val loss 5.0808\nThe current learning rate: 0.00011\nEpoch 4000: train loss 4.7862, val loss 4.7828\nThe current learning rate: 0.00011\nEpoch 4500: train loss 4.5576, val loss 4.5624\nThe current learning rate: 0.00011\nEpoch 5000: train loss 4.3553, val loss 4.3527\nThe current learning rate: 0.00012\nEpoch 5500: train loss 4.2011, val loss 4.1935\nThe current learning rate: 0.00012\nEpoch 6000: train loss 4.0441, val loss 4.0495\nThe current learning rate: 0.00013\nEpoch 7000: train loss 3.8128, val loss 3.8149\nThe current learning rate: 0.00014\nEpoch 7500: train loss 3.7053, val loss 3.7054\nThe current learning rate: 0.00015\nEpoch 8000: train loss 3.6070, val loss 3.6116\nThe current learning rate: 0.00015\nEpoch 8500: train loss 3.5363, val loss 3.5391\nThe current learning rate: 0.00016\nEpoch 9000: train loss 3.4562, val loss 3.4565\nThe current learning rate: 0.00017\nEpoch 9500: train loss 3.3856, val loss 3.3845\nThe current learning rate: 0.00018\nEpoch 10000: train loss 3.3181, val loss 3.3192\nThe current learning rate: 0.00019\nEpoch 10500: train loss 3.2494, val loss 3.2533\nThe current learning rate: 0.00020\nEpoch 11000: train loss 3.1892, val loss 3.1961\nThe current learning rate: 0.00021\nEpoch 11500: train loss 3.1267, val loss 3.1290\nThe current learning rate: 0.00022\nEpoch 12000: train loss 3.0733, val loss 3.0837\nThe current learning rate: 0.00023\nEpoch 12500: train loss 3.0358, val loss 3.0364\nThe current learning rate: 0.00024\nEpoch 13000: train loss 2.9877, val loss 2.9887\nThe current learning rate: 0.00025\nEpoch 13500: train loss 2.9401, val loss 2.9499\nThe current learning rate: 0.00026\nEpoch 14000: train loss 2.9026, val loss 2.9026\nThe current learning rate: 0.00027\nEpoch 14500: train loss 2.8606, val loss 2.8617\nThe current learning rate: 0.00028\nEpoch 15000: train loss 2.8230, val loss 2.8167\nThe current learning rate: 0.00029\nEpoch 15500: train loss 2.7768, val loss 2.7792\nThe current learning rate: 0.00030\nEpoch 16000: train loss 2.7460, val loss 2.7432\nThe current learning rate: 0.00031\nEpoch 16500: train loss 2.7060, val loss 2.7140\nThe current learning rate: 0.00032\nEpoch 17000: train loss 2.6870, val loss 2.6935\nThe current learning rate: 0.00033\nEpoch 17500: train loss 2.6518, val loss 2.6561\nThe current learning rate: 0.00034\nEpoch 18000: train loss 2.6153, val loss 2.6223\nThe current learning rate: 0.00035\nEpoch 18500: train loss 2.5803, val loss 2.5887\nThe current learning rate: 0.00036\nEpoch 19000: train loss 2.5498, val loss 2.5602\nThe current learning rate: 0.00037\nEpoch 19500: train loss 2.5237, val loss 2.5320\nThe current learning rate: 0.00038\nEpoch 20000: train loss 2.4932, val loss 2.5053\nThe current learning rate: 0.00039\nEpoch 20500: train loss 2.4718, val loss 2.4843\nThe current learning rate: 0.00040\nEpoch 21000: train loss 2.4482, val loss 2.4439\nThe current learning rate: 0.00041\nEpoch 21500: train loss 2.4215, val loss 2.4284\nThe current learning rate: 0.00042\nEpoch 22000: train loss 2.4052, val loss 2.4170\nThe current learning rate: 0.00043\nEpoch 22500: train loss 2.3839, val loss 2.3859\nThe current learning rate: 0.00044\nEpoch 23000: train loss 2.3646, val loss 2.3717\nThe current learning rate: 0.00045\nEpoch 23500: train loss 2.3511, val loss 2.3524\nThe current learning rate: 0.00045\nEpoch 24000: train loss 2.3286, val loss 2.3298\nThe current learning rate: 0.00046\nEpoch 24500: train loss 2.3103, val loss 2.3235\nThe current learning rate: 0.00047\nEpoch 25000: train loss 2.2962, val loss 2.3011\nThe current learning rate: 0.00047\nEpoch 25500: train loss 2.2806, val loss 2.2803\nThe current learning rate: 0.00048\nEpoch 26000: train loss 2.2615, val loss 2.2705\nThe current learning rate: 0.00048\nEpoch 26500: train loss 2.2543, val loss 2.2579\nThe current learning rate: 0.00049\nEpoch 27000: train loss 2.2366, val loss 2.2375\nThe current learning rate: 0.00049\nEpoch 27500: train loss 2.2133, val loss 2.2276\nThe current learning rate: 0.00049\nEpoch 28000: train loss 2.2026, val loss 2.2049\nThe current learning rate: 0.00050\nEpoch 28500: train loss 2.1974, val loss 2.2075\nThe current learning rate: 0.00050\nEpoch 29000: train loss 2.1879, val loss 2.1879\nThe current learning rate: 0.00050\nEpoch 29500: train loss 2.1666, val loss 2.1754\nThe current learning rate: 0.00050\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\nvalidation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n\nplt.plot(train_loss_list_converted, 'g', label='train_loss')\nplt.plot(validation_loss_list_converted, 'r', label='validation_loss')\nplt.xlabel(\"Steps - Every 500 epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T07:28:11.838190Z","iopub.execute_input":"2025-07-09T07:28:11.838543Z","iopub.status.idle":"2025-07-09T07:28:12.051859Z","shell.execute_reply.started":"2025-07-09T07:28:11.838524Z","shell.execute_reply":"2025-07-09T07:28:12.051225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#Load the model\nmodel = GPT(config)\ndevice =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\nbest_model_params_path = \"best_model_params.pt\"\nmodel.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T07:28:12.052706Z","iopub.execute_input":"2025-07-09T07:28:12.052985Z","iopub.status.idle":"2025-07-09T07:28:12.215232Z","shell.execute_reply.started":"2025-07-09T07:28:12.052962Z","shell.execute_reply":"2025-07-09T07:28:12.214618Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"sentence = \"Once upon a time there was a pumpkin.\"\ncontext = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\ny = model.generate(context, 200)\nprint(enc.decode(y.squeeze().tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T07:28:12.215985Z","iopub.execute_input":"2025-07-09T07:28:12.216250Z","iopub.status.idle":"2025-07-09T07:28:13.320632Z","shell.execute_reply.started":"2025-07-09T07:28:12.216224Z","shell.execute_reply":"2025-07-09T07:28:13.319919Z"}},"outputs":[{"name":"stdout","text":"Once upon a time there was a pumpkin. The pumpkin was warm and bright. Everyone was coming out of the cabin in the backyard. The pumpkin was so warm and comfy. Everyone wanted to know if it was warm,, it seemed spicy in the potato was splashing there.\n\nFinally, a big splash of wind blew water onto the potato. The pumpkin had hurt a lot. The pumpkin was free and the pumpkin was happy! It began to jump out and make a happy voice. LittleEd the pumpkin started running again.\n\nSuddenly, the pumpkin heard a loud noise. It sparkly, and the pumpkin went in! The pumpkin was very angry, so courageous. Foreing made the pumpkin into the chamber, brightly, and wave. The pumpkin shook the pumpkin to make a funny sound.\n\nThe pumpkin was amazed. It was nothing impossible to jump beautiful. After a good changed, the pie a magical rainy day was again.\n\nThe pumpkin never used its bunch knows about the pumpkin he had seen.M\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sentence = \"Once upon a time there was a king tall and brave.\"\ncontext = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\ny = model.generate(context, 200)\nprint(enc.decode(y.squeeze().tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T07:39:42.812497Z","iopub.execute_input":"2025-07-09T07:39:42.813337Z","iopub.status.idle":"2025-07-09T07:39:43.750446Z","shell.execute_reply.started":"2025-07-09T07:39:42.813311Z","shell.execute_reply":"2025-07-09T07:39:43.749604Z"}},"outputs":[{"name":"stdout","text":"Once upon a time there was a king tall and brave. He was carrying a big strain on a button. He was determined to use it. \n\nSuddenly the strong king rang. He said please was not a or Max. He used Susan's secret rod to permit the round machine and strong numbers style.\n\nThe people saw a big machine. There were toys, dolls, novels, and dirt and gems. Now they did go into a big box, but the afternoon was almost as well. \n\nAs they were walking down the wall, the lion hugged the small radio.Birdy saw something shiny in the corner. drofunctional flew out of the box and noticed there was in a hole. Sammy was curious to find the most about their words - like that everyone was covered in dirt. He remembered the noise was just as the power of it - the forest.Once upon a time, there was a little girl named Jenny from where she could draw on paper. Annie loved her diary, but her diary was too small to touch her\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"sentence = \"A little princess very pretty lived in her huge castle.\"\ncontext = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\ny = model.generate(context, 200)\nprint(enc.decode(y.squeeze().tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T07:40:39.179386Z","iopub.execute_input":"2025-07-09T07:40:39.179986Z","iopub.status.idle":"2025-07-09T07:40:40.129208Z","shell.execute_reply.started":"2025-07-09T07:40:39.179960Z","shell.execute_reply":"2025-07-09T07:40:40.128514Z"}},"outputs":[{"name":"stdout","text":"A little princess very pretty lived in her huge castle. The pastry was stuck and wanted to keep her favorite spell safe in its spaceship. Everyone wanted to help her, but they didn't know how of the spell would happen.\n\nSuddenly, the pastry answered in a little voice! The little planet had an idea! Everyone was special - the yummy taste of the palace. The little princess was so happy she was able to help the novel.\n\nAll of a sudden kinds of magical shapes they all got up and put on their mom's suitcase. The seedierled in the big tree, then proceeded to bloom. TheJennifer was so happy and shared her special words. The special treat tied a flag over its skills that everyone would laugh and go asleep.Once upon a time, there was a little girl called Sue. She loved to climb. One day, she saw a little bird flying high in the sky. She decided she thought it was so pretty. \n\nSue asked, \"What is that?\" The bird replied,\n","output_type":"stream"}],"execution_count":15}]}